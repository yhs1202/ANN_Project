{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csvs_dir) -> tuple:\n",
    "    train = np.empty((0, 64))\n",
    "    valid = np.empty((0, 64))\n",
    "    for csv_name in sorted(os.listdir(csvs_dir)):\n",
    "        if csv_name.endswith('csv'):\n",
    "            csv_path = os.path.join(csvs_dir,csv_name)\n",
    "            class_name = csv_path.split('/')[-1].split('_')[0]\n",
    "            class_name = int(class_name.lstrip('0'))\n",
    "            # print(class_name)   # 1~26\n",
    "            val = np.loadtxt(csv_path,delimiter=',')\n",
    "            class_value = np.full((val.shape[0], ), class_name) # label\n",
    "            val = np.column_stack((val, class_value))\n",
    "            # print(val.shape)\n",
    "            train_ = val[:int(len(val)*0.9), :]\n",
    "            valid_ = val[int(len(val)*0.9):, :]\n",
    "            # print(train_.shape)\n",
    "            # print(valid_.shape)\n",
    "            train = np.concatenate((train, train_), axis=0)\n",
    "            valid = np.concatenate((valid, valid_), axis=0)\n",
    "    train = np.random.permutation(train)     \n",
    "    valid = np.random.permutation(valid)\n",
    "    train_data = train[:, :63]\n",
    "    train_labels = train[:, -1]\n",
    "    valid_data = valid[:, :63]\n",
    "    valid_labels = valid[:, -1]\n",
    "    return (train_data, train_labels), (valid_data, valid_labels)\n",
    "\n",
    "def test_load_data(csvs_dir) -> tuple:\n",
    "    test = np.empty((0, 64))\n",
    "    for csv_name in sorted(os.listdir(csvs_dir)):\n",
    "        if csv_name.endswith('csv'):\n",
    "            csv_path = os.path.join(csvs_dir,csv_name)\n",
    "            class_name = csv_path.split('/')[-1].split('_')[0]\n",
    "            class_name = int(class_name.lstrip('0'))\n",
    "            # print(class_name)   # 1~26\n",
    "            val = np.loadtxt(csv_path,delimiter=',')\n",
    "            class_value = np.full((val.shape[0], ), class_name) # label\n",
    "            val = np.column_stack((val, class_value))\n",
    "            test_ = val[:, :]\n",
    "            test = np.concatenate((test, test_), axis=0)     \n",
    "    test = np.random.permutation(test)\n",
    "    test_data = test[:, :63]\n",
    "    test_labels = test[:, -1]\n",
    "    return (test_data, test_labels)\n",
    "\n",
    "def plot_acc_loss(h):\n",
    "    plt.figure(figsize=(15.6, 4.8), dpi=100)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(h.history['accuracy'])\n",
    "    plt.plot(h.history['val_accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc=0)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(h.history['loss'])\n",
    "    plt.plot(h.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc=0)\n",
    "    plt.show()\n",
    "\n",
    "def build_model():\n",
    "    input_shape = (63,)\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(256, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(26, activation='softmax'))\n",
    "    # model.add(layers.Dense(64, activation='relu'))\n",
    "    model.compile(optimizer=optimizers.SGD(momentum=0.9, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    csvs_dir = '/Users/hsyoon/Downloads/dataset2/csv'\n",
    "    (train_data, train_labels), (valid_data, valid_labels) = load_data(csvs_dir)\n",
    "    train_data.reshape(-1, 63)\n",
    "    train_labels = to_categorical(train_labels-1)\n",
    "    valid_labels = to_categorical(valid_labels-1)\n",
    "    test_csvs_dir = '/Users/hsyoon/Downloads/dataset_valid/csv'\n",
    "    (test_data, test_labels) = test_load_data(test_csvs_dir)\n",
    "    test_labels = to_categorical(test_labels-1)\n",
    "    \n",
    "    model = build_model()\n",
    "    history = model.fit(train_data, train_labels, epochs=1000, validation_data=(valid_data, valid_labels))\n",
    "    loss, acc = model.evaluate(test_data, test_labels)\n",
    "    print(\"test_acc:\", round(acc, 4))\n",
    "    print(\"test_loss:\", round(loss, 4))\n",
    "    plot_acc_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
